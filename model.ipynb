{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_csv('train.csv')\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        # BytesList won't unpack a string from an EagerTensor.\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_gender(g):\n",
    "    return 0 if g == 'male' else 1\n",
    "\n",
    "def decode_gender(g):\n",
    "    return 'male' if g== 0 else 'female'\n",
    "\n",
    "def encode_ticket(ticket):\n",
    "    t = ticket.split()\n",
    "\n",
    "    if t[-1].isalpha():\n",
    "        return 0\n",
    "    return int(t[-1])\n",
    "\n",
    "def encode_cabin(cabin):\n",
    "    if not cabin: # handle NaN\n",
    "        return 0,0\n",
    "    \n",
    "    # todo : parse string part\n",
    "\n",
    "    # todo : parse numeric part\n",
    "    return 0, 0\n",
    "\n",
    "def encode_embarked(embarked_class):\n",
    "    if embarked_class == 'S': return 1\n",
    "    if embarked_class == 'C': return 2\n",
    "    if embarked_class == 'Q': return 3\n",
    "    return 0\n",
    "\n",
    "def serialize_titanic_data(pass_id, label, pclass, name, age,sibsp,parch, ticket, fare, cabin, embarked, gender):\n",
    "    ticket = encode_ticket(ticket)\n",
    "    embarked = encode_embarked(embarked)\n",
    "    gender = encode_gender(gender)\n",
    "    # cabin_type, cabin_id = encode_cabin(cabin)\n",
    "\n",
    "    X = [pass_id, label, pclass, age, ticket, fare, gender, embarked]\n",
    "    y = label\n",
    "    return X, y\n",
    "    # ============ FOR TFRECORDS ======================\n",
    "    \n",
    "    # FIXME : not gonna use Name for now\n",
    "    # if label:\n",
    "    #     feature = {\n",
    "    #         'pass_id' : _int64_feature(pass_id),\n",
    "    #         'label' : _int64_feature(label),\n",
    "    #         'pclass' : _int64_feature(pclass),\n",
    "    #         'sibsp' : _int64_feature(sibsp),\n",
    "    #         'parch' : _int64_feature(parch),\n",
    "    #         'ticket' : _int64_feature(ticket),\n",
    "    #         'fare' : _float_feature(fare),\n",
    "    #         'embarked' : _int64_feature(embarked),\n",
    "    #         'gender' : _int64_feature(gender),\n",
    "    #         'cabin_type' : _int64_feature(cabin_type),\n",
    "    #         'cabin_id' : _int64_feature(cabin_id),\n",
    "    #     }\n",
    "    # else:\n",
    "    #     feature = {\n",
    "    #         'pass_id' : _int64_feature(pass_id),\n",
    "    #         'pclass' : _int64_feature(pclass),\n",
    "    #         'sibsp' : _int64_feature(sibsp),\n",
    "    #         'parch' : _int64_feature(parch),\n",
    "    #         'ticket' : _int64_feature(ticket),\n",
    "    #         'fare' : _float_feature(fare),\n",
    "    #         'embarked' : _int64_feature(embarked),\n",
    "    #         'gender' : _int64_feature(gender),\n",
    "    #         'cabin_type' : _int64_feature(cabin_type),\n",
    "    #         'cabin_id' : _int64_feature(cabin_id),\n",
    "    #     }\n",
    "\n",
    "    # # Create a Features message using tf.train.Example\n",
    "\n",
    "    # example_proto = tf.train.Example(\n",
    "    #     features=tf.train.Features(feature=feature)\n",
    "    # )\n",
    "    # return example_proto.SerializeToString()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['Ticket']\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train =[], []\n",
    "for _, row in train_set.iterrows():\n",
    "    pass_id, pclass, name, age,sibsp,parch, ticket, fare, cabin, embarked, gender = row.PassengerId, \\\n",
    "                row.Pclass, row.Name, row.Age, row.SibSp, row.Parch, row.Ticket, row.Fare, row.Cabin, row.Embarked, row.Sex \n",
    "    label = row.Survived\n",
    "    X , y = serialize_titanic_data(pass_id, label, pclass, name, age,sibsp,parch, ticket, fare, cabin, embarked, gender)\n",
    "    for i,x in enumerate(X):\n",
    "        if math.isnan(x):\n",
    "            X[i] = -1\n",
    "    X_train.append(X)\n",
    "    y_train.append(y)\n",
    "    \n",
    "# print(y_train)\n",
    "train_ds = tf.data.Dataset.from_tensors((X_train, y_train))\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeTFRecord(filename='test.tfrecord', df=None):\n",
    "    with tf.io.TFRecordWriter(filename) as writer:\n",
    "        for _, row in df.iterrows():\n",
    "            pass_id, pclass, name, age,sibsp,parch, ticket, fare, cabin, embarked, gender = row.PassengerId, \\\n",
    "                 row.Pclass, row.Name, row.Age, row.SibSp, row.Parch, row.Ticket, row.Fare, row.Cabin, row.Embarked, row.Sex\n",
    "            try:\n",
    "                label = row.Survived\n",
    "            except AttributeError:\n",
    "                label = None\n",
    "\n",
    "            data = serialize_titanic_data(pass_id, label, pclass, name, age,sibsp,parch, ticket, fare, cabin, embarked, gender)\n",
    "            writer.write(data)\n",
    "\n",
    "            \n",
    "        # for i in range(df):\n",
    "        #     # example = serialize_example(\n",
    "        #     #     feature0[i], feature1[i], feature2[i], feature3[i])\n",
    "        #     # writer.write(example)\n",
    "        #     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writeTFRecord('train.tfrecord', train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_ds = tf.data.TFRecordDataset('train.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example = None\n",
    "# for raw_record in raw_ds.take(1):\n",
    "#     example = tf.train.Example()\n",
    "#     example.ParseFromString(raw_record.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set = pd.read_csv('test.csv')\n",
    "# writeTFRecord('test.tfrecord', test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(40,activation='relu', input_shape=[8]))\n",
    "    model.add(Dense(20, activation='relu', input_shape=[40]))\n",
    "    model.add(Dense(10, activation='relu', input_shape = [20]))\n",
    "    model.add(Dense(1, activation='softmax', input_shape = [10]))\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "    model.build(input_shape=[8])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 40)                360       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 20)                820       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,401\n",
      "Trainable params: 1,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.       0.       3.     ...   7.25     0.       1.    ]\n",
      " [  2.       1.       1.     ...  71.2833   1.       2.    ]\n",
      " [  3.       1.       3.     ...   7.925    1.       1.    ]\n",
      " ...\n",
      " [889.       0.       3.     ...  23.45     1.       1.    ]\n",
      " [890.       1.       1.     ...  30.       0.       2.    ]\n",
      " [891.       0.       3.     ...   7.75     0.       3.    ]]\n",
      "[0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 0 1\n",
      " 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0\n",
      " 1 0 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0\n",
      " 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1\n",
      " 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0\n",
      " 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0\n",
      " 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1\n",
      " 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0\n",
      " 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0\n",
      " 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1\n",
      " 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0\n",
      " 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_ds.take(1):\n",
    "    X= X.numpy()\n",
    "    y = y.numpy()\n",
    "    print(X)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " Received a label value of 1 which is outside the valid range of [0, 1).  Label values: 0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\n (defined at c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\backend.py:5113)\n]] [Op:__inference_train_function_7567]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:\nIn[0] sparse_categorical_crossentropy/Reshape_1 (defined at c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\backend.py:5109)\t\nIn[1] sparse_categorical_crossentropy/Reshape (defined at c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\backend.py:3561)\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.2544.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.2544.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.2544.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.2544.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.2544.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 652, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\alex7\\AppData\\Local\\Temp\\ipykernel_30108\\3814295206.py\", line 1, in <module>\n>>>     m.fit(train_ds, epochs = 200)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n>>>     loss = self.compiled_loss(\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n>>>     loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n>>>     losses = call_fn(y_true, y_pred)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\losses.py\", line 245, in call\n>>>     return ag_fn(y_true, y_pred, **self._fn_kwargs)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\losses.py\", line 1737, in sparse_categorical_crossentropy\n>>>     return backend.sparse_categorical_crossentropy(\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\backend.py\", line 5113, in sparse_categorical_crossentropy\n>>>     res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [83]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 58\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     59\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  Received a label value of 1 which is outside the valid range of [0, 1).  Label values: 0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\n (defined at c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\backend.py:5113)\n]] [Op:__inference_train_function_7567]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:\nIn[0] sparse_categorical_crossentropy/Reshape_1 (defined at c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\backend.py:5109)\t\nIn[1] sparse_categorical_crossentropy/Reshape (defined at c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\backend.py:3561)\n\nOperation defined at: (most recent call last)\n>>>   File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.2544.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.2544.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.2544.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.2544.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.2544.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 461, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 450, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 652, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2768, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2814, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3012, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3191, in run_ast_nodes\n>>>     if await self.run_code(code, result, async_=asy):\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3251, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\alex7\\AppData\\Local\\Temp\\ipykernel_30108\\3814295206.py\", line 1, in <module>\n>>>     m.fit(train_ds, epochs = 200)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n>>>     loss = self.compiled_loss(\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n>>>     loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n>>>     losses = call_fn(y_true, y_pred)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\losses.py\", line 245, in call\n>>>     return ag_fn(y_true, y_pred, **self._fn_kwargs)\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\losses.py\", line 1737, in sparse_categorical_crossentropy\n>>>     return backend.sparse_categorical_crossentropy(\n>>> \n>>>   File \"c:\\Users\\alex7\\Desktop\\repos\\ai\\tf-kaggle-titanic\\env\\lib\\site-packages\\keras\\backend.py\", line 5113, in sparse_categorical_crossentropy\n>>>     res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n>>> "
     ]
    }
   ],
   "source": [
    "m.fit(train_ds, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 3, 22.0, 21171, 7.25, 0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "m.predict(tf.data.Dataset.from_tensors(X_train[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = pd.read_csv('test.csv')\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, pid = [], []\n",
    "for _, row in test_set.iterrows():\n",
    "    pass_id, pclass, name, age,sibsp,parch, ticket, fare, cabin, embarked, gender = row.PassengerId, \\\n",
    "                row.Pclass, row.Name, row.Age, row.SibSp, row.Parch, row.Ticket, row.Fare, row.Cabin, row.Embarked, row.Sex \n",
    "    label = None\n",
    "    X , y = serialize_titanic_data(pass_id, label, pclass, name, age,sibsp,parch, ticket, fare, cabin, embarked, gender)\n",
    "    X_test.append(X)\n",
    "    pid.append(pass_id)\n",
    "\n",
    "    \n",
    "# print(y_train)\n",
    "test_ds = tf.data.Dataset.from_tensors((X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = m.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_pred = zip(pid, list(preds))\n",
    "with open('submission.csv', 'w') as f:\n",
    "    for el in id_to_pred:\n",
    "        f.write(f\"{el[0]},{int(el[1][0])}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e0751dbbc5c506070938ad6b30cb2abab8f6c7f65ae20458f34af5460bc911d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
